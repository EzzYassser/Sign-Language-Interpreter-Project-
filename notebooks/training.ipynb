{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNwWQNyLs+/fFA6GUBaFbi0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"43mT03ChtOq2"},"outputs":[],"source":["# Cell 1 - Install packages\n","!pip install mediapipe==0.10.21 tensorflow==2.12.0 scikit-learn==1.2.2 matplotlib==3.7.1 textblob==0.17.1 opencv-python==4.7.0.72\n","\n","# Cell 2 - Verify installations\n","import pkg_resources\n","for pkg in ['mediapipe', 'tensorflow', 'scikit-learn', 'matplotlib', 'textblob', 'opencv-python']:\n","    print(f\"{pkg}: {pkg_resources.get_distribution(pkg).version}\")\n","\n","# Cell 3 - Restart runtime (Runtime -> Restart runtime) before proceeding"]},{"cell_type":"code","source":["# After restart, run this cell first to verify everything loaded correctly\n","import mediapipe\n","import tensorflow\n","import sklearn\n","import matplotlib\n","import textblob\n","import cv2\n","print(\"All imports working!\")"],"metadata":{"id":"-qny9Iuut6Hs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from sklearn.preprocessing import OneHotEncoder\n","import matplotlib.pyplot as plt\n","import mediapipe as mp\n","import cv2\n"],"metadata":{"id":"mHCtmXHqucv2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Re-mount Drive to ensure all files are accessible\n","from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"SpgWaElruffK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initializing the Model\n","mpHands = mp.solutions.hands\n","hands = mpHands.Hands(\n","\tstatic_image_mode=True,\n","\tmodel_complexity=1,\n","\tmin_detection_confidence=0.5,\n","\tmin_tracking_confidence=0.5,\n","\tmax_num_hands=2)"],"metadata":{"id":"1tviGxS1vMAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define paths\n","data_dir = '/content/drive/MyDrive/asl-dataset-v1/asl-dataset-v1/data'\n","\n","# Define the 26 letter classes we want to keep\n","valid_classes = [chr(ord('A') + i) for i in range(26)]  # A-Z\n","\n","# Collect all image file paths and their corresponding class labels\n","file_paths = []\n","labels = []\n","\n","for class_dir in os.listdir(data_dir):\n","    # Only process directories that are in our valid_classes list\n","    if class_dir in valid_classes and os.path.isdir(os.path.join(data_dir, class_dir)):\n","        class_path = os.path.join(data_dir, class_dir)\n","        for img_file in os.listdir(class_path):\n","            # Skip hidden files like .DS_Store\n","            if not img_file.startswith('.'):\n","                file_paths.append(os.path.join(class_path, img_file))\n","                labels.append(class_dir)\n","\n","file_paths = np.array(file_paths)\n","labels = np.array(labels)\n","class_names = np.unique(labels)\n","\n","# Verify we have exactly 26 classes\n","print(\"Classes found:\", class_names)\n","assert len(class_names) == 26, f\"Expected 26 classes but found {len(class_names)}\"\n","\n","\n","def load_images(file_paths):\n","    images = []\n","    valid_labels = []\n","    count = 0\n","    for file_path, label in zip(file_paths, labels):\n","\n","        img = cv2.imread(file_path)\n","        # Convert BGR image to RGB image\n","        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        # Process the RGB image\n","        results = hands.process(imgRGB)\n","        if results.multi_hand_landmarks:\n","            #Used for data normalization\n","            x_min = min([landmark.x for landmark in results.multi_hand_landmarks[0].landmark])\n","            y_min = min([landmark.y for landmark in results.multi_hand_landmarks[0].landmark])\n","            x_max = max([landmark.x for landmark in results.multi_hand_landmarks[0].landmark])\n","            y_max = max([landmark.y for landmark in results.multi_hand_landmarks[0].landmark])\n","            w = x_max - x_min\n","            h = y_max - y_min\n","            #Generate normlized data List with its flipped version, and flatten\n","            landmarks      = [(   (landmark.x - x_min) / w , (landmark.y - y_min) / h ) for landmark in results.multi_hand_landmarks[0].landmark]\n","            landmarks_Flip = [(1-((landmark.x - x_min) / w), (landmark.y - y_min) / h ) for landmark in results.multi_hand_landmarks[0].landmark]\n","            landmarks = list(sum(landmarks, ()))\n","            landmarks_Flip = list(sum(landmarks_Flip, ()))\n","            #Append to the processed dataset. X(images), y(valid_labels)\n","            images.append(landmarks)\n","            valid_labels.append(label)\n","            images.append(landmarks_Flip)\n","            valid_labels.append(label)\n","        else:\n","            count += 1\n","\n","\n","    print(\"Missed = {}\".format(count))\n","    return np.array(images), np.array(valid_labels)\n","# Load all images\n","images, valid_labels = load_images(file_paths)\n","\n","# Create stratified train/test split\n","train_files, test_files, train_labels, test_labels = train_test_split(\n","    images, valid_labels, test_size=0.3, stratify=valid_labels, random_state=42\n",")\n","# Further split the test set into validation and test sets\n","val_files, test_files, val_labels, test_labels = train_test_split(\n","    test_files, test_labels, test_size=0.5, stratify=test_labels, random_state=42\n",")\n","encoder = OneHotEncoder(categories='auto', sparse=False)\n","# Reshape labels for OneHotEncoder\n","train_labels_reshaped = train_labels.reshape(-1, 1)\n","val_labels_reshaped = val_labels.reshape(-1, 1)\n","test_labels_reshaped = test_labels.reshape(-1, 1)\n","# Fit and transform labels\n","train_labels_encoded = encoder.fit_transform(train_labels_reshaped)\n","val_labels_encoded = encoder.transform(val_labels_reshaped)\n","test_labels_encoded = encoder.transform(test_labels_reshaped)\n","\n","# Check the shapes of the datasets\n","print(f\"Train files shape: {train_files.shape}\")\n","print(f\"Train labels shape: {train_labels_encoded.shape}\")\n","print(f\"Validation files shape: {val_files.shape}\")\n","print(f\"Validation labels shape: {val_labels_encoded.shape}\")\n","print(f\"Test files shape: {test_files.shape}\")\n","print(f\"Test labels shape: {test_labels_encoded.shape}\")"],"metadata":{"id":"-5iRmHuGuvhd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a simple CNN model\n","\n","# Build the model\n","model = Sequential()\n","model.add(Dense(64, input_dim=42, activation='relu'))  # First hidden layer with 64 neurons\n","model.add(Dropout(0.5))  # Dropout to prevent overfitting\n","model.add(Dense(128, activation='relu'))  # Second hidden layer with 128 neurons\n","model.add(Dropout(0.5))  # Dropout to prevent overfitting\n","model.add(Dense(128, activation='relu'))  # Second hidden layer with 128 neurons\n","model.add(Dropout(0.5))  # Dropout to prevent overfitting\n","model.add(Dense(26, activation='softmax'))  # Output layer\n","\n","\n","# Compile the model\n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Define callbacks\n","checkpoint = ModelCheckpoint('c:/final_model/model.keras', save_best_only=True, monitor='val_accuracy', mode='max')\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=3, min_lr=0.001)\n","\n","# Train the model\n","#steps_per_epoch = len(train_files) // train_generator.batch_size\n","#validation_steps = len(val_files) // validation_generator.batch_size\n","\n","history = model.fit(\n","    train_files, train_labels_encoded,\n","    batch_size = 64,\n","    #steps_per_epoch=steps_per_epoch,\n","    epochs=100,\n","    validation_data=(val_files, val_labels_encoded),\n","    #validation_steps=validation_steps,\n","    callbacks=[checkpoint, early_stopping, reduce_lr]\n",")\n","\n","# Evaluate on test data\n","test_loss, test_acc = model.evaluate(test_files, test_labels_encoded )\n","print(f'Test accuracy: {test_acc}')"],"metadata":{"id":"gEWDw5AeGDWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model.summary()"],"metadata":{"id":"glKvgovSIlde"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","y_pred = model.predict(test_files)\n","y_pred = np.argmax(y_pred, axis=1)\n","y_true = np.argmax(test_labels_encoded, axis=1)"],"metadata":{"id":"zWfFR-o2Is4E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","\n","accuracy = accuracy_score(y_true, y_pred)\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","f1_score = f1_score(y_true, y_pred, average='weighted')\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1_score)\n","\n","print(classification_report(y_true, y_pred))\n","\n","\n"],"metadata":{"id":"Qc6vH4jsI2qu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(8, 6))\n","ax = plt.subplot()\n","sns.heatmap(cm, annot=True, ax=ax)  # Annotate cells with values\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])\n","ax.yaxis.set_ticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])\n","\n","plt.show()"],"metadata":{"id":"EBSNjTYaI5SV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_bounding_box(landmarks, image_width, image_height, scale=1.2):\n","    x_coords = [landmark.x * image_width for landmark in landmarks.landmark]\n","    y_coords = [landmark.y * image_height for landmark in landmarks.landmark]\n","    x_min, x_max = int(min(x_coords)), int(max(x_coords))\n","    y_min, y_max = int(min(y_coords)), int(max(y_coords))\n","\n","    # Calculate the center of the bounding box\n","    x_center = (x_min + x_max) // 2\n","    y_center = (y_min + y_max) // 2\n","\n","    # Calculate the size of the bounding box\n","    box_size = max(x_max - x_min, y_max - y_min) * scale\n","\n","    # Ensure the bounding box is a square\n","    half_size = int(box_size // 2)\n","\n","    # Calculate new min and max coordinates\n","    x_min_new = max(x_center - half_size, 0)\n","    x_max_new = min(x_center + half_size, image_width)\n","    y_min_new = max(y_center - half_size, 0)\n","    y_max_new = min(y_center + half_size, image_height)\n","\n","    return x_min_new, y_min_new, x_max_new, y_max_new\n","\n","\n"],"metadata":{"id":"_ZdriWqBJC1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","from textblob import TextBlob\n","\n","smoothing_window_size = 5\n","autocorrection_threshold = 3\n","\n","def smooth_predictions(predictions, window_size = smoothing_window_size):\n","    smoothed = []\n","    for i in range(len(predictions) - window_size + 1):\n","        window = predictions[i:i + window_size]\n","        most_common = Counter(window).most_common(1)[0][0]\n","        smoothed.append(most_common)\n","    return smoothed\n","\n","def remove_redundant(predictions, threshold=4):\n","    filtered = []\n","    last_char = predictions[0]\n","    count = 0\n","\n","    for char in predictions:\n","        if char == last_char:\n","            count += 1\n","        else:\n","            if count >= threshold:\n","                filtered.append(last_char)\n","            count = 1\n","            last_char = char\n","    if count >= threshold:\n","            filtered.append(last_char)\n","\n","    return filtered\n","\n","def process_predicted_word(letters_list):\n","    letters_list = letters_list\n","    #if input is too small -> don't do processing\n","    if len(letters_list) < smoothing_window_size:\n","        return ''.join(letters_list).lower()\n","    else:\n","        smoothing = smooth_predictions(letters_list)\n","        filter_redundants= remove_redundant(smoothing)\n","        if len(filter_redundants) <= autocorrection_threshold:\n","            return ''.join(filter_redundants).lower()\n","        autocorrected = str(TextBlob(''.join(filter_redundants).lower()).correct())\n","        return autocorrected\n","\n","\n","#FOR DEMONSTRATION\n","\n","x = ['h','h','h','h','h','x','a','a','a','a','x','x','a','a','a','p','p','p','p','p','y','y','y','y','y','y']\n","print(\"input: \",x)\n","print(\"input flatten: \",''.join(x))\n","x = np.array(smooth_predictions(x))\n","#smooth_predictions(x.tolist())\n","print(\"Smoothing: \",''.join(x))\n","x = np.array(remove_redundant(x))\n","print(\"Removing Redundants: \",''.join(x))\n","x = str(TextBlob(''.join(x)).correct())\n","print(\"Autocorrecting: \",x)\n","\n","\n","'''\n","x = ['G', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'Y', 'Y', 'B', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'C', 'D']\n","process_predicted_word(x)\n","str(TextBlob('hapy').correct())\n","'''"],"metadata":{"id":"3aoDhExMJGoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import pickle\n","import numpy as np\n","\n","#Save the model architecture to a JSON string\n","model_json = model.to_json()\n","\n","# Save the model weights to a numpy array\n","model_weights = model.get_weights()\n","\n","# Create a dictionary to store the model architecture and weights\n","model_dict = {\n","    'model_json': model_json,\n","    'model_weights': model_weights\n","}\n","\n","# Save the dictionary to a pickle file\n","with open('c:/final_model/model.pkl', 'wb') as f:\n","    pickle.dump(model_dict, f)"],"metadata":{"id":"t3MtmPMDJLkF"},"execution_count":null,"outputs":[]}]}